{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Parte 1:** Importanción de librerías"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Suprimiendo los Warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importando las librerías para trabajar CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential         \n",
    "\n",
    "from keras.layers import Convolution2D        \n",
    "from keras.layers import MaxPooling2D       \n",
    "from keras.layers import Flatten            \n",
    "from keras.layers import Dense \n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Parte 2:** Construcción de la CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se crea y se inicializa la CNN\n",
    "classifier = Sequential()\n",
    "\n",
    "#Paso 1 - Convolución\n",
    "classifier.add(Convolution2D(\n",
    "    filters=32,\n",
    "    kernel_size=(3,3),\n",
    "    input_shape = (64,64,3),\n",
    "    activation=\"relu\"\n",
    "))\n",
    "\n",
    "#Paso 2 - Max Pooling\n",
    "classifier.add(MaxPooling2D(\n",
    "    pool_size=(2,2)\n",
    "))\n",
    "\n",
    "#Se agrega otra capa de convolución y de max pooling para mejorar la red\n",
    "classifier.add(Convolution2D(\n",
    "    filters=32,\n",
    "    kernel_size=(3,3),\n",
    "    activation=\"relu\"\n",
    "))\n",
    "\n",
    "classifier.add(MaxPooling2D(\n",
    "    pool_size=(2,2)\n",
    "))\n",
    "\n",
    "#Paso 3 - Flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "#Paso 4 - Full Connection\n",
    "classifier.add(Dense(\n",
    "    units=128,\n",
    "    activation=\"relu\"\n",
    "))\n",
    "\n",
    "classifier.add(Dense(\n",
    "    units=1,\n",
    "    activation=\"sigmoid\"\n",
    "))\n",
    "\n",
    "#Compilación de la CNN\n",
    "classifier.compile(\n",
    "    optimizer = \"adam\",\n",
    "    loss = \"binary_crossentropy\",\n",
    "    metrics = [\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Parte 3:** Ajustar la imágenes para entrenar la CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "Epoch 1/25\n",
      "200/200 [==============================] - 98s 480ms/step - loss: 0.6752 - accuracy: 0.5721 - val_loss: 0.6175 - val_accuracy: 0.6955\n",
      "Epoch 2/25\n",
      "200/200 [==============================] - 79s 393ms/step - loss: 0.6006 - accuracy: 0.6731 - val_loss: 0.5641 - val_accuracy: 0.7130\n",
      "Epoch 3/25\n",
      "200/200 [==============================] - 67s 335ms/step - loss: 0.5724 - accuracy: 0.7005 - val_loss: 0.5652 - val_accuracy: 0.7220\n",
      "Epoch 4/25\n",
      "200/200 [==============================] - 97s 486ms/step - loss: 0.5480 - accuracy: 0.7176 - val_loss: 0.5487 - val_accuracy: 0.7230\n",
      "Epoch 5/25\n",
      "200/200 [==============================] - 87s 433ms/step - loss: 0.5223 - accuracy: 0.7362 - val_loss: 0.5119 - val_accuracy: 0.7550\n",
      "Epoch 6/25\n",
      "200/200 [==============================] - 81s 403ms/step - loss: 0.5045 - accuracy: 0.7462 - val_loss: 0.5117 - val_accuracy: 0.7555\n",
      "Epoch 7/25\n",
      "200/200 [==============================] - 107s 537ms/step - loss: 0.4857 - accuracy: 0.7620 - val_loss: 0.5088 - val_accuracy: 0.7590\n",
      "Epoch 8/25\n",
      "200/200 [==============================] - 75s 376ms/step - loss: 0.4730 - accuracy: 0.7728 - val_loss: 0.4885 - val_accuracy: 0.7610\n",
      "Epoch 9/25\n",
      "200/200 [==============================] - 75s 372ms/step - loss: 0.4702 - accuracy: 0.7731 - val_loss: 0.4907 - val_accuracy: 0.7735\n",
      "Epoch 10/25\n",
      "200/200 [==============================] - 75s 377ms/step - loss: 0.4452 - accuracy: 0.7884 - val_loss: 0.5096 - val_accuracy: 0.7585\n",
      "Epoch 11/25\n",
      "200/200 [==============================] - 76s 379ms/step - loss: 0.4438 - accuracy: 0.7905 - val_loss: 0.5194 - val_accuracy: 0.7645\n",
      "Epoch 12/25\n",
      "200/200 [==============================] - 74s 371ms/step - loss: 0.4305 - accuracy: 0.7964 - val_loss: 0.5241 - val_accuracy: 0.7610\n",
      "Epoch 13/25\n",
      "200/200 [==============================] - 79s 393ms/step - loss: 0.4278 - accuracy: 0.7981 - val_loss: 0.4588 - val_accuracy: 0.7905\n",
      "Epoch 14/25\n",
      "200/200 [==============================] - 75s 372ms/step - loss: 0.4140 - accuracy: 0.8060 - val_loss: 0.4909 - val_accuracy: 0.7710\n",
      "Epoch 15/25\n",
      "200/200 [==============================] - 75s 373ms/step - loss: 0.4017 - accuracy: 0.8140 - val_loss: 0.4741 - val_accuracy: 0.7805\n",
      "Epoch 16/25\n",
      "200/200 [==============================] - 74s 370ms/step - loss: 0.3875 - accuracy: 0.8231 - val_loss: 0.4767 - val_accuracy: 0.7880\n",
      "Epoch 17/25\n",
      "200/200 [==============================] - 76s 378ms/step - loss: 0.3814 - accuracy: 0.8295 - val_loss: 0.4660 - val_accuracy: 0.7845\n",
      "Epoch 18/25\n",
      "200/200 [==============================] - 72s 358ms/step - loss: 0.3737 - accuracy: 0.8321 - val_loss: 0.4921 - val_accuracy: 0.7785\n",
      "Epoch 19/25\n",
      "200/200 [==============================] - 72s 358ms/step - loss: 0.3678 - accuracy: 0.8321 - val_loss: 0.4646 - val_accuracy: 0.7920\n",
      "Epoch 20/25\n",
      "200/200 [==============================] - 73s 364ms/step - loss: 0.3533 - accuracy: 0.8440 - val_loss: 0.4678 - val_accuracy: 0.7930\n",
      "Epoch 21/25\n",
      "200/200 [==============================] - 73s 365ms/step - loss: 0.3521 - accuracy: 0.8424 - val_loss: 0.4566 - val_accuracy: 0.8005\n",
      "Epoch 22/25\n",
      "200/200 [==============================] - 63s 312ms/step - loss: 0.3386 - accuracy: 0.8504 - val_loss: 0.4574 - val_accuracy: 0.8020\n",
      "Epoch 23/25\n",
      "200/200 [==============================] - 63s 313ms/step - loss: 0.3208 - accuracy: 0.8575 - val_loss: 0.6013 - val_accuracy: 0.7585\n",
      "Epoch 24/25\n",
      "200/200 [==============================] - 63s 315ms/step - loss: 0.3180 - accuracy: 0.8610 - val_loss: 0.4742 - val_accuracy: 0.8000\n",
      "Epoch 25/25\n",
      "200/200 [==============================] - 63s 312ms/step - loss: 0.3023 - accuracy: 0.8668 - val_loss: 0.4605 - val_accuracy: 0.8055\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20be1eddee0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "training_dataset = train_datagen.flow_from_directory(\n",
    "    directory='dataset/training_set/',\n",
    "    target_size=(64, 64),\n",
    "    batch_size=40,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "testing_dataset = test_datagen.flow_from_directory(\n",
    "    directory='dataset/test_set/',\n",
    "    target_size=(64, 64),\n",
    "    batch_size=40,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "classifier.fit_generator(\n",
    "    training_dataset,\n",
    "    steps_per_epoch=200,\n",
    "    epochs=25,\n",
    "    validation_data=testing_dataset,\n",
    "    validation_steps=50\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
